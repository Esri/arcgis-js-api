<?xml version="1.0" encoding="UTF-8"?>

<snippets>

<snippet name="alignToPixelCenter"><![CDATA[
  vec4 alignToPixelCenter(vec4 clipCoord, vec2 widthHeight) {
    // From clip space to (0 : 1), bias towards right pixel edge
    vec2 xy = vec2(.500123) + .5 * clipCoord.xy / clipCoord.w;

    // Size of a pixel in range (0 : 1)
    vec2 pixelSz = vec2(1.0) / widthHeight;

    // Round to nearest pixel center
    vec2 ij = (floor(xy * widthHeight) + vec2(0.5)) * pixelSz;

    // Convert back to clip space
    vec2 result = (ij * 2.0 - vec2(1.0)) * clipCoord.w;

    return vec4(result, clipCoord.zw);
  }
]]></snippet>

<snippet name="alignToPixelOrigin"><![CDATA[
  vec4 alignToPixelOrigin(vec4 clipCoord, vec2 widthHeight) {
    // From clip space to (0 : 1),
    vec2 xy = vec2(.5) + .5 * clipCoord.xy / clipCoord.w;

    // Size of a pixel in range (0 : 1)
    vec2 pixelSz = vec2(1.0) / widthHeight;

    // Round to nearest pixel border, (0 : 1)
    vec2 ij = floor((xy + .5 * pixelSz) * widthHeight) * pixelSz;

    // Convert back to clip space
    vec2 result = (ij * 2.0 - vec2(1.0)) * clipCoord.w;

    return vec4(result, clipCoord.zw);
  }
]]></snippet>

<snippet name="float2rgba"><![CDATA[
	vec4 float2rgba(const in float v) {
		vec4 enc = vec4(1.0, 255.0, 65025.0, 16581375.0) * v;
		enc = fract(enc);
		enc -= enc.yzww * vec4(1.0/255.0, 1.0/255.0, 1.0/255.0, 0.0);
		return enc;
	}
]]></snippet>

<snippet name="rgba2float"><![CDATA[
	float rgba2float(vec4 rgba) {
		return dot(rgba, vec4(1.0, 1.0/255.0, 1.0/65025.0, 1.0/16581375.0));
	}
]]></snippet>

<snippet name="calcFragDepth"><![CDATA[
	#extension GL_OES_standard_derivatives : enable

	float calcFragDepth(const in float depth) {
		//calc polygon offset
		const float SLOPE_SCALE = 2.0;
		const float BIAS = 2.0 * .000015259;		// 1 / (2^16 - 1)
		float m = max(abs(dFdx(depth)), abs(dFdy(depth)));
		float result = depth + SLOPE_SCALE * m + BIAS;
		return clamp(result, .0, .999999);
	}
]]></snippet>

<snippet name="evalShadow"><![CDATA[
	$rgba2float

	// "matrix" parameter used to have const qualifier as well, but IE11 couldn't deal with it at time of writing.
	// once IE11 is fine with it, const should probably be re-introduced
	float evalShadow(const in vec3 vpos, const in float depth, const in sampler2D depthTex, const int num, const in vec4 distance, in mat4 matrix[4], const in float halfPxSz) {
		//choose correct cascade
		int i = depth < distance[1] ? 0 : depth < distance[2] ? 1 : depth < distance[3] ? 2 : 3;

		if (i >= num) return .0;

		mat4 mat = i == 0 ? matrix[0] : i == 1 ? matrix[1] : i == 2 ? matrix[2] : matrix[3];

		vec4 lv = mat * vec4(vpos, 1.0);
		lv.xy /= lv.w;

		//vertex completely outside? -> no shadow
		vec3 lvpos = .5 * lv.xyz + vec3(.5);
		if (lvpos.z >= 1.0) return .0;
		if (lvpos.x < .0 || lvpos.x > 1.0 || lvpos.y < .0 || lvpos.y > 1.0) return .0;

		//calc coord in cascade texture
		vec2 uv = vec2(float(i - 2 * (i / 2)) *.5, float(i / 2) * .5) + .5 * lvpos.xy;

		float texSize = .5 / halfPxSz;

		//filter, offset by half pixels
		vec2 st = fract((vec2(halfPxSz) + uv) * texSize);

		float s00 = rgba2float(texture2D(depthTex, uv + vec2(-halfPxSz, -halfPxSz))) < lvpos.z ? 1.0 : .0;
		float s10 = rgba2float(texture2D(depthTex, uv + vec2(halfPxSz, -halfPxSz))) < lvpos.z ? 1.0 : .0;
		float s11 = rgba2float(texture2D(depthTex, uv + vec2(halfPxSz, halfPxSz))) < lvpos.z ? 1.0 : .0;
		float s01 = rgba2float(texture2D(depthTex, uv + vec2(-halfPxSz, halfPxSz))) < lvpos.z ? 1.0 : .0;

		return mix(mix(s00, s10, st.x), mix(s01, s11, st.x), st.y);
	}
]]></snippet>


<!--
	Scene Lighting Definitions:
	================================================

	defines:
		- SH_ORDER: 1|2|3
	input:
		- normal: vec3
		- albedo: vec3
	  - shadow: float
		- ssao: float
	return:
	  - color: vec3
-->
<snippet name="sceneLightingDefinitions"><![CDATA[
	$viewingMode

	// main light
	/////////////////////////////////////////
	uniform vec3 lightingMainDirection;
	uniform vec3 lightingMainIntensity;

	// ambient lighting
	/////////////////////////////////////////
	#ifndef SH_ORDER
		#define SH_ORDER 2
	#endif

	#if SH_ORDER == 0
		uniform vec3 lightingAmbientSH0;
	#elif SH_ORDER == 1
		uniform vec4 lightingAmbientSH_R;
		uniform vec4 lightingAmbientSH_G;
		uniform vec4 lightingAmbientSH_B;
	#elif SH_ORDER == 2
		uniform vec3 lightingAmbientSH0;
		uniform vec4 lightingAmbientSH_R1;
		uniform vec4 lightingAmbientSH_G1;
		uniform vec4 lightingAmbientSH_B1;
		uniform vec4 lightingAmbientSH_R2;
		uniform vec4 lightingAmbientSH_G2;
		uniform vec4 lightingAmbientSH_B2;
	#endif

	// special tweaking
	//////////////////////////////////////////
		uniform float lightingFixedFactor;
		uniform float lightingGlobalFactor;

		uniform float ambientBoostFactor;

	// evaluation
	//////////////////////////////////////////

	vec3 evaluateSceneLighting(vec3 normal, vec3 albedo, float shadow, float ssao, vec3 additionalLight) {
		// evaluate the main light
		float dotVal = mix(clamp(-dot(normal, lightingMainDirection), 0.0, 1.0), 1.0, lightingFixedFactor);
		vec3 mainLight = (1.0 - shadow) * lightingMainIntensity * dotVal;

		// evaluate the sh ambient light
		#if SH_ORDER == 0
			vec3 ambientLight = 0.282095 * lightingAmbientSH0;
		#elif SH_ORDER == 1
			vec4 sh0 = vec4(
				0.282095,
				0.488603 * normal.x,
				0.488603 * normal.z,
				0.488603 * normal.y
			);
			vec3 ambientLight = vec3(
				dot(lightingAmbientSH_R, sh0),
				dot(lightingAmbientSH_G, sh0),
				dot(lightingAmbientSH_B, sh0)
			);
		#elif SH_ORDER == 2
			vec3 ambientLight = 0.282095 * lightingAmbientSH0;

			vec4 sh1 = vec4(
				0.488603 * normal.x,
				0.488603 * normal.z,
				0.488603 * normal.y,
				1.092548 * normal.x * normal.y
			);
			vec4 sh2 = vec4(
				1.092548 * normal.y * normal.z,
				0.315392 * (3.0 * normal.z * normal.z - 1.0),
				1.092548 * normal.x * normal.z,
				0.546274 * (normal.x * normal.x - normal.y * normal.y)
			);
			ambientLight += vec3(
				dot(lightingAmbientSH_R1, sh1),
				dot(lightingAmbientSH_G1, sh1),
				dot(lightingAmbientSH_B1, sh1)
			);
			ambientLight += vec3(
				dot(lightingAmbientSH_R2, sh2),
				dot(lightingAmbientSH_G2, sh2),
				dot(lightingAmbientSH_B2, sh2)
			);
		#endif
		ambientLight *= (1.0 - ssao);

		// inverse gamma correction on the albedo color
		float gamma = 2.1;
		vec3 albedoGammaC = pow(albedo, vec3(gamma));

		// physically correct BRDF normalizes by PI
		const float PI = 3.14159;
		vec3 totalLight = mainLight + ambientLight + additionalLight;
		totalLight = min(totalLight, vec3(PI, PI, PI));
		vec3 outColor = vec3((albedoGammaC / PI) * (totalLight));

		// apply gamma correction to the computed color
		outColor = pow(outColor, vec3(1.0/gamma));

		return outColor;
	}

]]></snippet>

<snippet name="sceneLightingAdditionalLightGlobal"><![CDATA[
	// heuristic lighting model originally used in the terrain shading
	// now used to generated additional ambient light
	#ifdef VIEWING_MODE_GLOBAL
		float vndl = -dot(normalize(vpos + localOrigin), lightingMainDirection);
	#else
		float vndl = -dot(vec3(0,0,1), lightingMainDirection);
	#endif
	float additionalAmbientScale = smoothstep(0.0, 1.0, clamp(vndl*2.5, 0.0, 1.0));
	vec3 additionalLight = ssao * lightingMainIntensity * additionalAmbientScale * ambientBoostFactor * lightingGlobalFactor;
]]></snippet>

<snippet name="normal2envTC"><![CDATA[
	vec2 normal2envTC(vec3 normal) {
		float v = .5 + .5 * asin(normal.y) * 0.63661977;
		float u = .5 - .5 * atan(normal.z, normal.x) * 0.31830988;
		return vec2(u, v);
	}
]]></snippet>

<snippet name="vertexShaderShowDepth"><![CDATA[
  $vsprecisionf

	uniform mat4 proj;
	attribute vec2 $position;
	attribute vec2 $uv0;
	varying vec2 vtc;

	void main(void) {
		gl_Position = proj * vec4($position.x, $position.y, .0, 1.0);
		vtc = $uv0;
	}
]]></snippet>

	<snippet name="fragmentShaderShowDepth"><![CDATA[
	$fsprecisionf

	uniform sampler2D depthTex;
	varying vec2 vtc;
	$rgba2float
	void main() {
	//	gl_FragColor = vec4(vec3(texture2D(depthTex, vtc).a), 1.0);
		gl_FragColor = vec4(rgba2float(texture2D(depthTex, vtc)));
	//	gl_FragColor = texture2D(depthTex, vtc);
	}
]]></snippet>

<snippet name="vsUVQuad"><![CDATA[
  $vsprecisionf

	attribute vec2 $position;
	varying vec2 uv;

	void main(void) {
		gl_Position = vec4($position.x, $position.y, .0, 1.0);
		uv = $position * .5 + vec2(.5);
	}
]]></snippet>

<snippet name="toScreenCoords"><![CDATA[
	vec4 toScreenCoords(vec3 vertex) {
		vec4 vClipSpace = proj * view * vec4((model * vec4(vertex, 1.0)).xyz, 1.0);
		vClipSpace.xy *= screenSize;
		return vClipSpace/abs(vClipSpace.w);
	}
]]></snippet>

<snippet name="vvUniforms"><![CDATA[
#if defined(VV_SIZE)
	#define VV_CUSTOM_MODEL_MATRIX
#endif

#if defined(VV_SIZE)
	uniform vec3 vvSizeMinSize;
	uniform vec3 vvSizeMaxSize;
	uniform vec3 vvSizeOffset;
	uniform vec3 vvSizeFactor;
#elif defined(VV_CUSTOM_MODEL_MATRIX)
	uniform vec3 vvSizeValue;
#endif

#ifdef VV_CUSTOM_MODEL_MATRIX
	uniform mat3 vvSymbolRotation;
#endif

#ifdef VV_CUSTOM_MODEL_MATRIX
	uniform vec3 vvSymbolAnchor;
#endif

#ifdef VV_COLOR
	#define VV_COLOR_N 8
	uniform float vvColorValues[VV_COLOR_N];
	uniform vec4 vvColorColors[VV_COLOR_N];
#endif

]]></snippet>

<snippet name="vvFunctions"><![CDATA[
// Evaluation of size
#if defined(VV_SIZE)
	vec3 vvGetScale(vec4 featureAttribute) {
		return clamp(vvSizeOffset + featureAttribute.x * vvSizeFactor, vvSizeMinSize, vvSizeMaxSize);
	}
#elif defined(VV_CUSTOM_MODEL_MATRIX)
	vec3 vvGetScale(vec4 featureAttribute) {
		return vvSizeValue;
	}
#endif

// Applying the model matrix
#ifdef VV_CUSTOM_MODEL_MATRIX
	vec4 vvTransformPosition(vec3 position, vec4 featureAttribute) {
		return vec4(vvSymbolRotation * (vvGetScale(featureAttribute) * (position + vvSymbolAnchor)), 1.0);
	}

	vec4 vvTransformNormal(vec3 normal, vec4 featureAttribute) {
		// Normal transform is the inverse transpose of model transform
		return vec4(vvSymbolRotation * normal / vvGetScale(featureAttribute), 1.0);
	}
#endif

#ifdef VV_COLOR
	vec4 vvGetColor(vec4 featureAttribute, float values[VV_COLOR_N], vec4 colors[VV_COLOR_N]) {
		float value = featureAttribute.y;
		if (value <= values[0]) {
			return colors[0];
		}

		for (int i = 1; i < VV_COLOR_N; ++i) {
			if (values[i] >= value) {
				float f = (value - values[i-1]) / (values[i] - values[i-1]);
				return mix(colors[i-1], colors[i], f);
			}
		}

		return colors[VV_COLOR_N - 1];
	}
#endif
]]></snippet>

<snippet name="rgb2hsv"><![CDATA[
vec3 rgb2hsv(vec3 c)
{
	vec4 K = vec4(0.0, -1.0 / 3.0, 2.0 / 3.0, -1.0);
	vec4 p = mix(vec4(c.bg, K.wz), vec4(c.gb, K.xy), step(c.b, c.g));
	vec4 q = mix(vec4(p.xyw, c.r), vec4(c.r, p.yzx), step(p.x, c.r));

	float d = q.x - min(q.w, q.y);
	float e = 1.0e-10;
	return vec3(abs(q.z + (q.w - q.y) / (6.0 * d + e)), d / (q.x + e), q.x);
}
]]></snippet>

<snippet name="hsv2rgb"><![CDATA[
vec3 hsv2rgb(vec3 c)
{
	vec4 K = vec4(1.0, 2.0 / 3.0, 1.0 / 3.0, 3.0);
	vec3 p = abs(fract(c.xxx + K.xyz) * 6.0 - K.www);
	return c.z * mix(K.xxx, clamp(p - K.xxx, 0.0, 1.0), c.y);
}
]]></snippet>

<snippet name="colorMixMode"><![CDATA[
$rgb2hsv
$hsv2rgb


/*
 * The color mix modes are encoded in the symbol color as follows:
 *  - Fully transparent symbols are represented with alpha 0 for
 *    all color mix modes (except ignore).
 *  - color mix mode ignore is encoded as multiply with white
 *  - the other 3 color mix modes (tint, replace, multiply) are
 *    equally distributed on the remaining 255 alpha values, which
 *    gives us 85 possible alpha values
 *
 * alpha             0 : fully transparent
 * alpha in [  1 -  85]: tint
 * alpha in [ 86 - 170]: replace
 * alpha in [171 - 255]: multiply
 */
vec4 decodeSymbolColor(vec4 symbolColor, out int colorMixMode) {
  float symbolAlpha = 0.0;

  const float maxTint = 85.0;
  const float maxReplace = 170.0;
  const float scaleAlpha = 3.0;

  if (symbolColor.a == 0.0) {
    colorMixMode = 1; // fully transparent -> multiply
    symbolAlpha = 0.0;
  }
  else if (symbolColor.a <= maxTint) {
    colorMixMode = 0; // tint
    symbolAlpha = scaleAlpha * symbolColor.a;
  }
  else if (symbolColor.a <= maxReplace) {
    colorMixMode = 3; // replace
    symbolAlpha = scaleAlpha * (symbolColor.a - maxTint);
  }
  else {
    colorMixMode = 1;  // multiply
    symbolAlpha = scaleAlpha * (symbolColor.a - maxReplace);
  }

  return vec4(symbolColor.rgb, symbolAlpha);
}

vec3 mixExternalColor(vec3 internalColor, vec3 textureColor, vec3 externalColor, int mode) {

  // workaround for artifacts in OSX using Intel Iris Pro
  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475
  vec3 internalMixed = internalColor * textureColor;
  vec3 allMixed = internalMixed * externalColor;

  if (mode == 1 /* multiply */) {
    return allMixed;
  }
  else if (mode == 2 /* ignore */ ) {
    return internalMixed;
  }
  else if (mode == 3 /* replace */ ) {
    return externalColor;
  }
  else {
    // tint (or something invalid)
    vec3 hsvIn = rgb2hsv(internalMixed);
    vec3 hsvTint = rgb2hsv(externalColor);
    vec3 hsvOut = vec3(hsvTint.x, hsvTint.y, hsvIn.z * hsvTint.z);
    return hsv2rgb(hsvOut);
  }
}

float mixExternalOpacity(float internalOpacity, float textureOpacity, float externalOpacity, int mode) {

  // workaround for artifacts in OSX using Intel Iris Pro
  // see: https://devtopia.esri.com/WebGIS/arcgis-js-api/issues/10475
  float internalMixed = internalOpacity * textureOpacity;
  float allMixed = internalMixed * externalOpacity;

  if (mode == 2 /* ignore */ ) {
    return internalMixed;
  }
  else if (mode == 3 /* replace */ ) {
    return externalOpacity;
  }
  else {
    // multiply or tint (or something invalid)
    return allMixed;
  }
}

]]></snippet>

<snippet name="highlightWrite"><![CDATA[
  // the following uniforms are common to all highlight shaders:
  // uniform sampler2D depthTex
  // uniform vec4 highlightViewportPixelSz
  float sceneDepth = texture2D(depthTex, (gl_FragCoord.xy - highlightViewportPixelSz.xy) * highlightViewportPixelSz.zw).r;
  if (gl_FragCoord.z > sceneDepth + 5e-6) {
    gl_FragColor = vec4(1.0, 1.0, 0.0, 1.0);
  }
  else {
    gl_FragColor = vec4(1.0, 0.0, 1.0, 1.0);
  }
]]></snippet>

<snippet name="screenSizePerspective"><![CDATA[
#ifdef SCREEN_SIZE_PERSPECTIVE

// These could be functions, but I wanted to make sure that they are inlined. Additionally,
// as macros, applying the scale works also for different types (float, vec2, etc).
// Note that the implementation here should be kept in sync with the corresponding
// CPU implementation (used for hitTest etc) in screenSizePerspectiveUtils.ts

// Transform the input minimum size (factor.z) so that, when comparing to it, we are
// excluding the 'padding' size (factor.w).
#define screenSizePerspectiveMinSize(/* float */ size, /* vec4 */ factor) (factor.z * (1.0 + 2.0 * factor.w  / size))

#define screenSizePerspectiveFactor(/* float */ absCosAngle) (absCosAngle * absCosAngle * absCosAngle)

#define screenSizePerspectiveScaleFactor(/* float */ absCosAngle, /* float */ distanceToCamera, /* vec4 */ params) vec4(min(params.x / (distanceToCamera - params.y), 1.0), screenSizePerspectiveFactor(absCosAngle), params.z, params.w)

// Factor is computed from screenSizePerspectiveScaleFactor
#define applyScreenSizePerspectiveScaleFactorFloat(/* float */ size, /* vec4 */ factor) max(mix(size * factor.x, size, factor.y), screenSizePerspectiveMinSize(size, factor))
#define screenSizePerspectiveScaleFloat(/* float */ size, /* float */ absCosAngle, /* float */ distanceToCamera, /* vec4 */ params) applyScreenSizePerspectiveScaleFactorFloat(size, screenSizePerspectiveScaleFactor(absCosAngle, distanceToCamera, params))

#define applyScreenSizePerspectiveScaleFactorVec2(/* vec2 */ size, /* vec4 */ factor) mix(size * clamp(factor.x, screenSizePerspectiveMinSize(size.y, factor) / size.y, 1.0), size, factor.y)
#define screenSizePerspectiveScaleVec2(/* vec2 */ size, /* float */ absCosAngle, /* float */ distanceToCamera, /* vec4 */ params) applyScreenSizePerspectiveScaleFactorVec2(size, screenSizePerspectiveScaleFactor(absCosAngle, distanceToCamera, params))

#endif
]]></snippet>

<snippet name="computeNormal"><![CDATA[
	#ifdef GROUND_NORMAL_SHADING
		#ifdef VIEWING_MODE_GLOBAL
			vec3 normal = normalize(vpos + localOrigin);
		#else
			vec3 normal = vec3(0,0,1);
		#endif
	#else
			// compute normal
		#ifndef DOUBLESIDED
				vec3 normal = vnormal;
		#else
				vec3 normal = dot(vnormal, viewDir)>0.0 ? -vnormal : vnormal;
		#endif
		normal = normalize(normal);
	#endif
]]></snippet>

</snippets>
